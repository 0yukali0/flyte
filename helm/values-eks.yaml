
#
# FLYTEADMIN
#

flyteadmin:
  replicaCount: 2
  # IAM role for SA: https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::<ACCOUNT-NUMBER>:role/iam-role-flyte

  resources:
    limits:
      ephemeral-storage: 200Mi
    requests:
      cpu: 50m
      ephemeral-storage: 200Mi
      memory: 200Mi

  service:
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "600"
      # TODO add security groups
      service.beta.kubernetes.io/aws-load-balancer-extra-security-groups: "sg-...,sg-...,sg-..."
      # TODO alter domain
      external-dns.alpha.kubernetes.io/hostname: "flyteadmin.subdomain.mydomain.com"
    type: LoadBalancer
    loadBalancerSourceRanges:
      # TODO change source ip range if desired
      - 0.0.0.0

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/name: flyteadmin
          topologyKey: kubernetes.io/hostname

#
# DATACATALOG
#

datacatalog:
  replicaCount: 2
  # IAM role for SA: https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::<ACCOUNT-NUMBER>:role/iam-role-flyte
  resources:
    limits:
      cpu: 500m
      ephemeral-storage: 200Mi
    requests:
      cpu: 50m
      ephemeral-storage: 200Mi
      memory: 200Mi
  service:
    annotations:
      cloud.google.com/load-balancer-type: Internal
    type: LoadBalancer
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/name: datacatalog
          topologyKey: kubernetes.io/hostname

#
# FLYTEPROPELLER
#

flytepropeller:
  replicaCount: 2
  # IAM role for SA: https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html
  serviceAccountAnnotations:
    eks.amazonaws.com/role-arn: arn:aws:iam::<ACCOUNT-NUMBER>:role/iam-role-flyte
  resources:
    limits:
      cpu: 500m
      ephemeral-storage: 200Mi
      memory: 500Mi
    requests:
      cpu: 50m
      ephemeral-storage: 200Mi
      memory: 200Mi
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/name: flytepropeller
          topologyKey: kubernetes.io/hostname

#
# FLYTECONSOLE
#

flyteconsole:
  replicaCount: 2
  resources:
    limits:
      cpu: 250m
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/name: flyteconsole
          topologyKey: kubernetes.io/hostname

#
# REDIS
#

redis:
  resources:
    requests:
      cpu: 100m
      memory: 250Mi

#
# POSTGRES
#

postgres:
  enabled: false

#
# MINIO
#

minio:
  enabled: false

#
# CONTOUR
#

contour:
  enabled: false

#
# SPARKOPERATOR
#

sparkoperator:
  enabled: true
  resources:
    limits:
      cpu: 1000m
      memory: 1000Mi
    requests:
      cpu: 50m
      memory: 250Mi

#
# PYTORCHOPERATOR
#

pytorchoperator:
  resources:
    limits:
      cpu: 1000m
      memory: 1000Mi
    requests:
      cpu: 50m
      memory: 250Mi

#
# COMMON
#

common:
  ingress:
    host: flyte.example.com
    annotations:
      # aws-load-balancer-controller v2.1 or higher is required - https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/
      kubernetes.io/ingress.class: alb
      alb.ingress.kubernetes.io/tags: service_instance=production
      alb.ingress.kubernetes.io/scheme: internet-facing
      alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig": { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
      # Instruct ALB Controller to not create multiple load balancers (and hence maintain a single endpoint for both GRPC and Http)
      alb.ingress.kubernetes.io/group.name: flytesystem
      # Replace certificate Arn with one deployed to your EKS cluster. Follow instructions in README.md
      alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:us-east-2:111111111111:certificate/e92fefd8-6197-4249-a524-431d611c9af6
      alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
  databaseSecret:
    name: db-pass
    secretManifest:
      # # Leave it empty if your secret already exists

      # # Else you can create your own secret object: 
      # # Necessary dependencies:
      # # - https://github.com/hashicorp/vault
      # # - https://github.com/godaddy/kubernetes-external-secrets

      # apiVersion: kubernetes-client.io/v1
      # kind: ExternalSecret
      # metadata:
      #   name: db-pass
      #   namespace: flyte
      # spec:
      #   backendType: vault
      #   vaultMountPoint: <MOUNT_PATH>
      #   vaultRole: <VAULT-ROLE>
      #   data:
      #   - name: pass.txt
      #     key: k8s/data/path/to/secret
      #     property: password

#
# CONFIGMAPS
#

configmap:
  db:
    database:
      port: 5432
      username: postgres
      host: <DB-NAME>
      dbname: flyte-development
      passwordPath: /etc/db/pass.txt
  remote_data:
    remoteData:
      region: us-east-1
      scheme: aws
  server:
    server:
      httpPort: 8088
      grpcPort: 8089
      security:
        secure: false
        useAuth: false
        allowCors: true
        allowedOrigins:
          # Accepting all domains for Sandbox installation
          - "*"
        allowedHeaders:
          - "Content-Type"
    scheduler:
      eventScheduler:
        scheme: aws
        region: us-east-1
        scheduleRole: arn:aws:iam::<ACCOUNT-NUMBER>:role/flyte_cron_scheduler_role
        targetName: arn:aws:sqs:us-east-1:<ACCOUNT-NUMBER>:flyte-cron-scheduler-queue
        scheduleNamePrefix: flyte
      workflowExecutor:
        scheme: aws
        region: us-east-1
        scheduleQueueName: flyte-cron-scheduler-queue
        accountId: <ACCOUNT-NUMBER>
        reconnectAttempts: 10
        reconnectDelaySeconds: 30
    notifications:
      type: aws
      region: us-east-1
      publisher:
        topicName: arn:aws:sns:us-east-1:<ACCOUNT-NUMBER>:flyte-notifications-topic
      processor:
        queueName: flyte-notifications-queue
        accountId: <ACCOUNT-NUMBER>
      emailer:
        subject: "Flyte: {{ project }}/{{ domain }}/{{ launch_plan.name }} has '{{ phase }}'"
        sender:  "flyte@example.com"
        body: |
          Execution {{ workflow.project }}/{{ workflow.domain }}/{{ workflow.name }}/{{ name }} has {{ phase }}.
          Details: https://flyte.example.com/console/projects/{{ project }}/domains/{{ domain }}/executions/{{ name }}.
          {{ error }}
    task_type_whitelist:
      spark:
        - project: flytetester
        - project: spark-workflows


  storage:
    storage:
      type: s3
      container: s3-bucket-for-flyte
      connection:
        auth-type: iam
        region: us-east-1

  task_resource_defaults:
    task_resources:
      defaults:
        cpu: 1000m
        memory: 1000Mi
        storage: 1000Mi
      limits:
        storage: 2000Mi

  core:
    propeller:
      rawoutput-prefix: s3://s3-bucket-for-flyte/
      workers: 40
      gc-interval: 12h
      max-workflow-retries: 50
      kube-client-config:
        qps: 100
        burst: 25
        timeout: 30s
      queue:
        sub-queue:
          type: bucket
          rate: 100
          capacity: 1000
      workflowStore:
        policy: "ResourceVersionCache"

  enabled_plugins:
    tasks:
      task-plugins:
        enabled-plugins:
          - container
          - sidecar
          - spark
          - k8s-array
          - pytorch
        default-for-task-types:
          container: container
          sidecar: sidecar
          spark: spark
          container_array: k8s-array
          pytorch: pytorch

  logger:
    logger:
      level: 5

  spark:
    plugins:
      spark:
        spark-config-default:
          - # We override the default credentials chain provider for Hadoop so that
            # it can use the serviceAccount based IAM role or ec2 metadata based.
            # This is more in line with how AWS works
          - spark.hadoop.fs.s3a.aws.credentials.provider: "com.amazonaws.auth.DefaultAWSCredentialsProviderChain"
          - spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version: "2"
          - spark.kubernetes.allocation.batch.size: "50"
          - spark.hadoop.fs.s3a.acl.default: "BucketOwnerFullControl"
          - spark.hadoop.fs.s3n.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
          - spark.hadoop.fs.AbstractFileSystem.s3n.impl: "org.apache.hadoop.fs.s3a.S3A"
          - spark.hadoop.fs.s3.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
          - spark.hadoop.fs.AbstractFileSystem.s3.impl: "org.apache.hadoop.fs.s3a.S3A"
          - spark.hadoop.fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
          - spark.hadoop.fs.AbstractFileSystem.s3a.impl: "org.apache.hadoop.fs.s3a.S3A"
          - spark.hadoop.fs.s3a.multipart.threshold: "536870912"
          - spark.blacklist.enabled: "true"
          - spark.blacklist.timeout: "5m"
          - spark.task.maxfailures: "8"

  ab_project_resource_quota: |
    apiVersion: v1
    kind: ResourceQuota
    metadata:
      name: project-quota
      namespace: {{ namespace }} 
    spec:
      hard:
        limits.cpu: {{ projectQuotaCpu }} 
        limits.memory: {{ projectQuotaMemory }}

  ac_project_copilot_dataconfig: |
    kind: ConfigMap
    apiVersion: v1
    metadata:
      name: flyte-data-config
      namespace: {{ namespace }}
    data:
      config.yaml: |
        storage:
          connection:
            auth-type: iam
            region: us-east-1
          type: s3
          container: my-s3-bucket
          enable-multicontainer: true
